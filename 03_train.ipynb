{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, ):\n",
    "        data_path = Path(\"data/processed\")\n",
    "        csv_files = list(data_path.glob(\"*.csv\"))\n",
    "\n",
    "        self.Ys = []\n",
    "        self.Xs = []\n",
    "\n",
    "        for f in csv_files:\n",
    "            df = pd.read_csv(f)\n",
    "\n",
    "            # interpolate missing values\n",
    "            df = df.interpolate(method=\"linear\", limit_direction=\"both\")\n",
    "\n",
    "            # trim to 1800 samples\n",
    "            df = df.iloc[:1800]\n",
    "\n",
    "            # extract features\n",
    "            self.Ys.append(df[[\"cursor_x\", \"cursor_y\"]].values.astype(np.float32))\n",
    "            self.Xs.append(df.drop(columns=[\"cursor_x\", \"cursor_y\"]).values.astype(np.float32))\n",
    "\n",
    "\n",
    "        self.data = list(zip(self.Xs, self.Ys))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pytorchLSTM(nn.Module):\n",
    "    def __init__(self, n_in, hidden_size, n_out):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_in = n_in\n",
    "        self.lstm = nn.LSTM(n_in, hidden_size, num_layers=1, batch_first = True)\n",
    "        self.output_layer = nn.Linear(hidden_size, n_out)\n",
    "\n",
    "        \n",
    "    def forward(self, X, hidden = None):\n",
    "        if hidden == None:\n",
    "            b =  X.shape[0]\n",
    "            hidden = (\n",
    "                torch.zeros(1, b, self.hidden_size).to(X.device),\n",
    "                torch.zeros(1, b, self.hidden_size).to(X.device)\n",
    "            )\n",
    "            out, hidden = self.lstm(X, hidden)\n",
    "            out = self.output_layer(out)\n",
    "        else:\n",
    "            out, hidden = self.lstm(X, hidden)\n",
    "            out = self.output_layer(out)\n",
    "        return out, hidden"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "hidden_size = 128\n",
    "lr = 1e-3\n",
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create the dataset and data loader\n",
    "dataset = CustomDataset()\n",
    "\n",
    "n_in = dataset.data[0][0].shape[1]\n",
    "n_out = dataset.data[0][1].shape[1]\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pytorchLSTM(n_in, hidden_size, n_out).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000],  Loss: 1690763.1250\n",
      "Epoch [11/1000],  Loss: 1689966.2500\n",
      "Epoch [21/1000],  Loss: 1682905.0000\n",
      "Epoch [31/1000],  Loss: 1677774.2500\n",
      "Epoch [41/1000],  Loss: 1673452.7500\n",
      "Epoch [51/1000],  Loss: 1669764.7500\n",
      "Epoch [61/1000],  Loss: 1666315.2500\n",
      "Epoch [71/1000],  Loss: 1663033.0000\n",
      "Epoch [81/1000],  Loss: 1659873.0000\n",
      "Epoch [91/1000],  Loss: 1656802.3750\n",
      "Epoch [101/1000],  Loss: 1653800.8750\n",
      "Epoch [111/1000],  Loss: 1650839.8750\n",
      "Epoch [121/1000],  Loss: 1647869.8750\n",
      "Epoch [131/1000],  Loss: 1644947.6250\n",
      "Epoch [141/1000],  Loss: 1641987.2500\n",
      "Epoch [151/1000],  Loss: 1639082.3750\n",
      "Epoch [161/1000],  Loss: 1636212.5000\n",
      "Epoch [171/1000],  Loss: 1633371.8750\n",
      "Epoch [181/1000],  Loss: 1630557.2500\n",
      "Epoch [191/1000],  Loss: 1627764.8750\n",
      "Epoch [201/1000],  Loss: 1624992.8750\n",
      "Epoch [211/1000],  Loss: 1622238.3750\n",
      "Epoch [221/1000],  Loss: 1619500.2500\n",
      "Epoch [231/1000],  Loss: 1616776.8750\n",
      "Epoch [241/1000],  Loss: 1614067.5000\n",
      "Epoch [251/1000],  Loss: 1611370.6250\n",
      "Epoch [261/1000],  Loss: 1608686.0000\n",
      "Epoch [271/1000],  Loss: 1606012.6250\n",
      "Epoch [281/1000],  Loss: 1603350.1250\n",
      "Epoch [291/1000],  Loss: 1600697.8750\n",
      "Epoch [301/1000],  Loss: 1598055.3750\n",
      "Epoch [311/1000],  Loss: 1595422.3750\n",
      "Epoch [321/1000],  Loss: 1592798.6250\n",
      "Epoch [331/1000],  Loss: 1590183.1250\n",
      "Epoch [341/1000],  Loss: 1587576.0000\n",
      "Epoch [351/1000],  Loss: 1584975.3750\n",
      "Epoch [361/1000],  Loss: 1582299.1250\n",
      "Epoch [371/1000],  Loss: 1579634.8750\n",
      "Epoch [381/1000],  Loss: 1576986.1250\n",
      "Epoch [391/1000],  Loss: 1574348.7500\n",
      "Epoch [401/1000],  Loss: 1571627.0000\n",
      "Epoch [411/1000],  Loss: 1568937.5000\n",
      "Epoch [421/1000],  Loss: 1566267.0000\n",
      "Epoch [431/1000],  Loss: 1563615.1250\n",
      "Epoch [441/1000],  Loss: 1560979.7500\n",
      "Epoch [451/1000],  Loss: 1558358.5000\n",
      "Epoch [461/1000],  Loss: 1555749.8750\n",
      "Epoch [471/1000],  Loss: 1553152.6250\n",
      "Epoch [481/1000],  Loss: 1550565.3750\n",
      "Epoch [491/1000],  Loss: 1547988.0000\n",
      "Epoch [501/1000],  Loss: 1545419.5000\n",
      "Epoch [511/1000],  Loss: 1542859.5000\n",
      "Epoch [521/1000],  Loss: 1540307.7500\n",
      "Epoch [531/1000],  Loss: 1537763.5000\n",
      "Epoch [541/1000],  Loss: 1535227.1250\n",
      "Epoch [551/1000],  Loss: 1532697.7500\n",
      "Epoch [561/1000],  Loss: 1530175.7500\n",
      "Epoch [571/1000],  Loss: 1527660.3750\n",
      "Epoch [581/1000],  Loss: 1525151.8750\n",
      "Epoch [591/1000],  Loss: 1522649.8750\n",
      "Epoch [601/1000],  Loss: 1520154.5000\n",
      "Epoch [611/1000],  Loss: 1517665.1250\n",
      "Epoch [621/1000],  Loss: 1515182.1250\n",
      "Epoch [631/1000],  Loss: 1512705.2500\n",
      "Epoch [641/1000],  Loss: 1510234.2500\n",
      "Epoch [651/1000],  Loss: 1507769.5000\n",
      "Epoch [661/1000],  Loss: 1505310.2500\n",
      "Epoch [671/1000],  Loss: 1502856.8750\n",
      "Epoch [681/1000],  Loss: 1500409.3750\n",
      "Epoch [691/1000],  Loss: 1497967.1250\n",
      "Epoch [701/1000],  Loss: 1495530.6250\n",
      "Epoch [711/1000],  Loss: 1493099.7500\n",
      "Epoch [721/1000],  Loss: 1490673.8750\n",
      "Epoch [731/1000],  Loss: 1488253.8750\n",
      "Epoch [741/1000],  Loss: 1485838.8750\n",
      "Epoch [751/1000],  Loss: 1483429.2500\n",
      "Epoch [761/1000],  Loss: 1481024.8750\n",
      "Epoch [771/1000],  Loss: 1478626.0000\n",
      "Epoch [781/1000],  Loss: 1476231.6250\n",
      "Epoch [791/1000],  Loss: 1473842.8750\n",
      "Epoch [801/1000],  Loss: 1471459.1250\n",
      "Epoch [811/1000],  Loss: 1469080.5000\n",
      "Epoch [821/1000],  Loss: 1466706.5000\n",
      "Epoch [831/1000],  Loss: 1464337.7500\n",
      "Epoch [841/1000],  Loss: 1461973.8750\n",
      "Epoch [851/1000],  Loss: 1459615.0000\n",
      "Epoch [861/1000],  Loss: 1457260.7500\n",
      "Epoch [871/1000],  Loss: 1454911.6250\n",
      "Epoch [881/1000],  Loss: 1452567.0000\n",
      "Epoch [891/1000],  Loss: 1450227.3750\n",
      "Epoch [901/1000],  Loss: 1447892.3750\n",
      "Epoch [911/1000],  Loss: 1445562.1250\n",
      "Epoch [921/1000],  Loss: 1443236.5000\n",
      "Epoch [931/1000],  Loss: 1440915.7500\n",
      "Epoch [941/1000],  Loss: 1438599.8750\n",
      "Epoch [951/1000],  Loss: 1436288.2500\n",
      "Epoch [961/1000],  Loss: 1433981.1250\n",
      "Epoch [971/1000],  Loss: 1431678.8750\n",
      "Epoch [981/1000],  Loss: 1429381.0000\n",
      "Epoch [991/1000],  Loss: 1427087.8750\n"
     ]
    }
   ],
   "source": [
    "hidden = None\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for i, (X, Y) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Detach the hidden state from the previous sequence\n",
    "        if hidden is not None:\n",
    "            hidden = (hidden[0].detach(), hidden[1].detach())\n",
    "\n",
    "        # Forward pass\n",
    "        outputs, hidden = model(X, hidden=hidden)\n",
    "        loss = criterion(outputs, Y)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    if epoch % 100 == 0 or epoch == 0:\n",
    "        print(f'Epoch [{epoch}/{num_epochs}],  Loss: {epoch_loss:.4f}')\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'models/lstm_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lmnh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
